{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "# the file name output you want to record into\n",
    "filename = \"recorded.wav\"\n",
    "# set the chunk size of 1024 samples\n",
    "chunk = 1024\n",
    "# sample format\n",
    "FORMAT = pyaudio.paInt16\n",
    "# mono, change to 2 if you want stereo\n",
    "channels = 1\n",
    "# 44100 samples per second\n",
    "sample_rate = 16000\n",
    "record_seconds = 3\n",
    "# initialize PyAudio object\n",
    "p = pyaudio.PyAudio()\n",
    "# open stream object as input & output\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=channels,\n",
    "                rate=sample_rate,\n",
    "                input=True,\n",
    "                output=True,\n",
    "                frames_per_buffer=chunk)\n",
    "frames = []\n",
    "print(\"Recording...\")\n",
    "for i in range(int(44100 / chunk * record_seconds)):\n",
    "    data = stream.read(chunk)\n",
    "    # if you want to hear your voice while recording\n",
    "    # stream.write(data)\n",
    "    frames.append(data)\n",
    "print(\"Finished recording.\")\n",
    "# stop and close stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "# terminate pyaudio object\n",
    "p.terminate()\n",
    "# save audio file\n",
    "# open the file in 'write bytes' mode\n",
    "wf = wave.open(filename, \"wb\")\n",
    "# set the channels\n",
    "wf.setnchannels(channels)\n",
    "# set the sample format\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "# set the sample rate\n",
    "wf.setframerate(sample_rate)\n",
    "# write the frames as bytes\n",
    "wf.writeframes(b\"\".join(frames))\n",
    "# close the file\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording\n",
      "rerding finished\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "fs = 44100  # Sample rate\n",
    "seconds = 3  # Duration of recording\n",
    "print(\"recording\")\n",
    "myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=2)\n",
    "sd.wait()  # Wait until recording is finished\n",
    "print(\"rerding finished\")\n",
    "#write('output.wav', fs, myrecording)  # Save as WAV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "write('output.wav', fs, myrecording)  # Save as WAV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0000000e+00,  0.0000000e+00],\n",
       "       [-3.0517578e-05,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00],\n",
       "       ...,\n",
       "       [ 2.4414062e-04,  9.1552734e-05],\n",
       "       [-4.2724609e-04, -2.4414062e-04],\n",
       "       [-3.0517578e-04, -4.8828125e-04]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrecording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features():\n",
    "    \n",
    "    # Sets the name to be the path to where the file is in my computer\n",
    "    #file_name = os.path.join(os.path.abspath('new_test_male_female')+'/'+str(files.file))\n",
    "    file_name=\"output.wav\"\n",
    "\n",
    "    # Loads the audio file as a floating point time series and assigns the default sample rate\n",
    "    # Sample rate is set to 22050 by default\n",
    "    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "\n",
    "    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "\n",
    "    # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "\n",
    "    # Computes a chromagram from a waveform or power spectrogram.\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes a mel-scaled spectrogram.\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes spectral contrast\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes the tonal centroid features (tonnetz)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "        \n",
    "    \n",
    "    # We add also the classes of each file as a label at the end\n",
    "    #label = files.label\n",
    "\n",
    "    return mfccs, chroma, mel, contrast, tonnetz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-216.06212663,  107.26244416,  -11.45021031,    8.78588115,\n",
       "         -11.69535366,   -6.98149182,  -17.99825906,   -5.11042861,\n",
       "         -21.69708962,   -3.15294334,  -26.48797404,   -5.08655349,\n",
       "         -14.06289304,  -11.05233166,   -3.70528049,   -7.00557151,\n",
       "         -14.54762973,   -0.76030355,  -12.41346543,   -6.64619337,\n",
       "         -14.52331249,   -4.20320206,  -12.79623574,   -0.94284558,\n",
       "          -7.97971036,   -2.53911042,   -7.50280454,   -4.93236316,\n",
       "          -2.91740778,   -7.19746652,   -1.29463767,   -2.30726496,\n",
       "          -2.13043316,   -2.75749793,   -4.53575799,   -0.78439972,\n",
       "          -3.61915367,   -2.04200675,   -0.95943751,   -0.78422541]),\n",
       " array([0.71017656, 0.6524587 , 0.57771175, 0.57187863, 0.53138484,\n",
       "        0.55354017, 0.60175842, 0.62975898, 0.62010916, 0.69108128,\n",
       "        0.72003321, 0.77083355]),\n",
       " array([3.75906606e-02, 3.23612756e-02, 5.88419062e-02, 3.04436792e+00,\n",
       "        2.47866981e+01, 2.90553594e+01, 2.41838783e+01, 3.39493388e+01,\n",
       "        1.04349548e+02, 1.15581147e+02, 3.13244692e+01, 1.15030320e+01,\n",
       "        2.07853694e+01, 9.45129451e+01, 9.77495143e+01, 4.17300684e+01,\n",
       "        5.17300353e+01, 5.92251123e+01, 8.01577577e+01, 4.77195238e+01,\n",
       "        3.46995374e+01, 1.52615114e+01, 1.21927697e+01, 1.45106539e+01,\n",
       "        5.92570912e+00, 3.96733348e+00, 3.63888073e+00, 3.13074283e+00,\n",
       "        3.03629680e+00, 2.66326145e+00, 2.67602636e+00, 2.63006701e+00,\n",
       "        4.86016383e+00, 3.84314573e+00, 2.00941474e+00, 1.47606670e+00,\n",
       "        2.25989187e+00, 2.52443888e+00, 1.08996909e+00, 1.32230675e+00,\n",
       "        1.99681139e+00, 3.43173124e+00, 2.95828915e+00, 2.30528230e+00,\n",
       "        1.74489948e+00, 2.33195946e+00, 1.26676390e+00, 3.85584517e-01,\n",
       "        3.76946182e-01, 5.11570144e-01, 1.03410232e+00, 7.87534072e-01,\n",
       "        4.60732823e-01, 5.77387556e-01, 6.77174198e-01, 5.91107182e-01,\n",
       "        5.92529104e-01, 5.39500051e-01, 1.02361772e+00, 5.89094942e-01,\n",
       "        3.11748773e-01, 6.30362569e-01, 3.98797821e-01, 3.14997649e-01,\n",
       "        3.64497363e-01, 8.95455982e-01, 5.28234692e-01, 2.76416345e-01,\n",
       "        1.85441209e-01, 1.88831637e-01, 2.73802933e-01, 6.20778141e-01,\n",
       "        8.90732990e-01, 6.24534551e-01, 3.79747271e-01, 2.95169150e-01,\n",
       "        2.27480567e-01, 1.04869777e-01, 8.41332906e-02, 9.19072133e-02,\n",
       "        7.49113727e-02, 7.46941552e-02, 6.79112617e-02, 6.42541800e-02,\n",
       "        8.11153009e-02, 1.14890251e-01, 2.04991006e-01, 3.88134607e-01,\n",
       "        4.02028609e-01, 3.14082091e-01, 2.83445490e-01, 1.57134266e-01,\n",
       "        6.77087755e-02, 8.34734233e-02, 4.07262165e-02, 1.15090995e-02,\n",
       "        9.18367943e-03, 4.26724559e-03, 3.27750598e-03, 3.05556772e-03,\n",
       "        2.49430149e-03, 2.62902156e-03, 3.29242697e-03, 3.34588725e-03,\n",
       "        3.05160057e-03, 3.59198417e-03, 3.65752499e-03, 7.09959094e-03,\n",
       "        1.53125397e-02, 2.99837589e-02, 4.64708346e-02, 2.24995966e-02,\n",
       "        7.58195373e-03, 3.26725911e-03, 2.62947189e-03, 2.91703873e-03,\n",
       "        3.94990766e-03, 7.79278214e-03, 6.67835795e-03, 9.06875371e-03,\n",
       "        7.70723966e-03, 5.16746984e-03, 6.53415508e-03, 2.60805125e-03,\n",
       "        6.31276026e-04, 1.50111376e-04, 1.95299720e-05, 4.64849873e-07]),\n",
       " array([29.08133777, 14.96421581, 16.95620286, 16.25705733, 16.5361905 ,\n",
       "        18.36409414, 41.15693207]),\n",
       " array([ 0.01206359, -0.00131405,  0.04291783,  0.00681114, -0.00162013,\n",
       "         0.00375374]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Loading Keras Model\n",
      "* Model Loaded\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    global model\n",
    "    model=load_model(\"D:\\\\Voice Classification\\\\Code\\\\Gender_Classifier\\\\trained_models\\\\Gender_Classifier_NN.h5\")\n",
    "    print(\"* Model Loaded\")\n",
    "\n",
    "# Again, the modified function to extract features from our new test data\n",
    "def extract_features(files):\n",
    "    \n",
    "    # Sets the name to be the path to where the file is in my computer\n",
    "    #file_name = os.path.join(os.path.abspath('new_test_male_female')+'/'+str(files.file))\n",
    "    file_name=\"D:\\\\Voice Classification\\\\Code\\\\project\\\\\"+files.file\n",
    "\n",
    "    # Loads the audio file as a floating point time series and assigns the default sample rate\n",
    "    # Sample rate is set to 22050 by default\n",
    "    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "\n",
    "    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "\n",
    "    # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "\n",
    "    # Computes a chromagram from a waveform or power spectrogram.\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes a mel-scaled spectrogram.\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes spectral contrast\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes the tonal centroid features (tonnetz)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "    \n",
    "    #removing file recorded\n",
    "    \n",
    "    return mfccs, chroma, mel, contrast, tonnetz\n",
    "\n",
    "def preprocess():\n",
    "    #features=pd.DataFrame({\"file\":os.listdir(\"D:\\\\Voice Classification\\\\Code\\\\project\\\\audio_files\\\\\")}).apply(extract_features,axis=1)\n",
    "    features=pd.DataFrame({\"file\":[\"output.wav\"]}).apply(extract_features,axis=1)\n",
    "    x=np.array(features)\n",
    "    features_new_test = []\n",
    "    for i in range(0, len(x)):\n",
    "        features_new_test.append(np.concatenate((x[i][0], x[i][1], x[i][2], x[i][3], x[i][4]), axis=0))\n",
    "    X_new_test = np.array(features_new_test)\n",
    "    ss = load(open('D:\\\\Voice Classification\\\\Code\\\\Gender_Classifier\\\\scaler.pkl', 'rb'))\n",
    "    X_new_test_scaled = ss.transform(X_new_test)\n",
    "    return X_new_test_scaled\n",
    "                       \n",
    "print(\"* Loading Keras Model\")\n",
    "#get_model()\n",
    "\n",
    "def record():\n",
    "\t#message = request.get_json(force=True)#just for formality\n",
    "\t#code for recording\n",
    "\tresponse={\n",
    "\t\t'result':'True'\n",
    "\t}\n",
    "\n",
    "def predict():\n",
    "\t#message = request.get_json(force=True)#just for formality\n",
    "    scaled_data=preprocess()\n",
    "    prediction = model.predict_classes(scaled_data)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
